# 11장 성능, 확장성

스레드를 사용하는 가장 큰 목적은 바로 성능을 높이고자 하는 것이다.

## 11.1 성능에 대해

스레드 간의 작업 내용을 조율하는 데 필요한 오버헤드(락 걸기, 신호 보내기, 메모리 동기화하기 등) 도 비용이라고 볼 수 있고, 컨텍스트 스위칭이 자주 발생한다는 점, 스레드를 생성하거나 제거하는 일이 빈번하다는 점, 여러 스레드를 효율적으로 스케쥴링해야 한다는 등의 부분도 모두 비용이다.

잘못 설계된 병렬 애플리케이션은 순차적으로 작업을 처리하는 프로그램보다 오히려 느리게 동작하는 경우도 간혹 생긴다.

### 11.1.1 성능 대 확장성

**서비스 시간, 대기 시간 등** : 특정 작업을 처리하는 속도가 "얼마나 빠르냐"
**용량, 처리량** : 동일한 자원을 갖고 있을 때 "얼마나 많은" 양의 일을 할 수 있는가

`확장성(scalability)은 CPU, 메모리, 디스크, I/O 처리 장치 등의 추가적인 장비를 사용해 처리량이나 용량을 얼마나 쉽게 키울 수 있는지를 말한다.`

병렬 프로그램 환경에서 확장성을 충분히 가질 수 있도록 애플리케이션을 설계하고 튜닝하는 방법은 기존에 해오던 일반적인 성능 최적화 방법과 다른 부분이 많다.

성능 튜닝 : 동일한 일을 더 적은 노력으로 하고자 하는 것 
확장성 튜닝 : 처리해야 할 작업을 병렬화해 시스템의 가용 자원을 더 많이 사용하면서 더 많은 일을 처리할 수 있도록 하는 방법을 많이 사용

### 11.1.2 성능 트레이드 오프 측정

트레이드 오프 : 완전 고용의 실현과 물가의 안정이라는 두 목표는, 실업률을 저하시키면 물가가 상승하고 물가를 안정시키려 하면 실업이 증가하는 이율배반의 관계가 형성한다. 따라서 두 목표가 양립할 수 없다는 주장이 나오는데, 이 경우 어느 한쪽을 위해 다른 쪽을 희생시키는 것을 `트레이드 오프`라고 한다.

성능을 최적화하는 다수의 경우에 코드의 가독성와 유지보수의 용이함을 비용으로 지불한다.

## 11.2 암달의 법칙

`암달의 법칙(Amdahl's law)`을 사용하면 병렬 작업과 순차 작업의 비율에 따라 하드웨어 자원을 추가로 투입했을 때 이론적으로 속도가 얼마나 빨라질지에 대한 예측 값을 얻을 수 있다.

순차적으로 실행돼야 하는 작업의 비율을 F라고 하고 하드웨어에 꽂혀있는 프로세서의 개수를 N이라고 할 때, 다음의 수식에 해당하는 정도까지 속도를 증가 시킬수 있다.

```math
a \le 1 / (F+ (1 - F) / N)
```

### 11.2.1 예제: 프레임웍 내부에 감춰져 있는 순차적 실행 구조

스레드 개수를 증가시킬 때마다 성능이 얼마나 빨라지는지를 기록해두고, 성능상의 차이점을 기반으로 순차적으로 처리하는 부분이 얼마만큼인지 추축해 볼 수 있다.

ConcurrentLinkedQueue는 프로세서의 개수에 해당하는 수치에 다다르면 더 이상 증가하지 않고 일정하게 유지되는 경향을 보인다.
동기화된 LinkedList 의 성능은 스레드가 3개 정도까지는 증가하다가 그 이후에는 동기화 관련 부하가 늘어나서 성능이 떨어진다. (컨텍스트 스위칭)

### 11.2.2 정성적인 암달의 법칙 적용 방법

## 11.3 스레드와 비용

## 11.3.1 컨텍스트 스위칭

CPU 개수보다 실행중인 스레드의 개수가 많다고 하면, 운영체제가 특정 스레드의 실행 스케줄을 선점하고 다른 스레드가 실행될 수 있도록 스케줄을 잡는다.
이처럼 하나의 스레드가 실행되다가 다른 스레드가 실행되는 순간 `컨텍스트 스위칭(CONTEXT SWITCHING)`이 일어난다.

대부분의 스레드 스케줄러는 실행 대기 중인 스레드가 밀려있다고 해도, 현재 실행 중인 스레드에게 최소한의 실행 시간을 보장해주는 정책을 취하고 있다.
그러면 컨텍스트 스위치에 들어가는 시간과 비용을 나누는 효과를 볼수 있고, 그 결과 인터럽트 받지 않고 실행할 수 있는 최소한의 시간을 보장받기 때문에 전체적인 성능이 향상되는 효과를 볼 수 있다.

대기 상태에 들어가는 연산을 많이 사용하는 프로그램(블로킹 I/O를 사용하거나, 락 대기 시간이 길거나, 상태 변수의 값을 기다리는 증)은 CPU를 주로 활용하는 프로그램보다 컨텍스트 스위치가 훨씬 많아지고, 따라서 스케줄링 부하가 늘어나면서 전체적인 처리량이 줄어든다. (넌블로킹 알고리즘을 사용하면 컨텍스트 스위칭에 소모되는 부하를 줄일 수 있다.)

## 11.3.2 메모리 동기화

synchronized와 volatile 키워드를 사용해 얻을 수 있는 가시정을 통해 메모리 배리어(memory barrier)라는 특별한 명령어를 사용할 수 있다.

메모리 배리어는 
* 캐시를 플러시하거나 무효화
* 하드웨어와 관련된 쓰기 버퍼를 플러시
* 실행 파이프라인을 늦출 수도 있다.

(단점)
* 여러가지 최적화 기법을 제대로 사용할 수 없게 돼 간접적인 성능 문제를 가져올 수 있다.
* 메모리 배리어를 사용하면 명령어 재배치를 대부분 할 수 없게 되기 때문이다.

최근에 사용하는 JVM은 대부분 다른 스레드와 경쟁할 가능성이 없다고 판단되는 부분에 락이 걸려 있다면 최적화 과정에서 해당 락을 사용하지 않도록 방지하는 기능을 제공하기도 한다.

## 11.3.3 블로킹

JVM은 스레드를 대기 상태에 둘 때 두 가지 방법을 사용할 수 있다.

* 첫번째 방법: 스핀대기(spin waiting), 즉 락을 확보할 때까지 계속해서 재시도 하는 방법
* 두번째 방법: 운영체제가 제공하는 기능을 사용해 스레드를 실제 대기 상태로 두는 방법

대기 시간이 짭을 경우 스핀 대기 방법이 효과적이고, 대기 시간이 긴 경우 운영체제의 기능을 호출하는 편이 효율적이다.

## 11.4 락 경쟁 줄이기

작업을 순차적으로 처리하면 확장성(scalability)을 놓치고, 작업을 병렬로 처리하면 컨텍스트 스위칭에 성능(performance)에 악영향을 준다.
그런데 `락을 놓고 경쟁하는 상황이 벌어지면 순차적으로 처리함과 동시에 컨텍스트 스위칭도 많이 일어나므로 확장성과 성능을 동시에 떨어뜨리는 원인이 된다.`

```
병렬 애플리케이션에서 확장성에 가장 큰 위협이 되는 존재는 바로 특정 자원을 독점적으로 사용하도록 제한하는 락이다.
```

락을 두고 발생하는 경쟁 상황의 두가지 원인
* 락을 얼마나 빈번하게 확보하려고 하는지
* 락을 확보하고 나면 해제할 때 까지 얼마나 오래 사용하는지

락 경쟁 조건을 줄일 수 있는 몇 가지 방법
* 락을 확보한 채로 유지되는 시간을 최대한 줄여라.
* 락을 확보하고자 요청하는 횟수를 최대한 줄여라
* 독점적인 락 대신 병렬성을 크게 높여주는 여러 가지 조율 방법을 사용하라

### 11.4.1 락 구역 좁히기

락 경쟁이 발생할 가능성을 줄이는 효과적인 방법 가운데 하나는 바로 락을 유지하는 시간을 줄이는 방법이다.
락이 꼭 필요하지 않은 코드를 synchronized 블록 밖으로 뽑아내어 락이 영향을 미치는 구역을 좁히면 락을 유지하는 시간을 줄 일 수 있다.
특히 I/O 작업과 같이 대기 시간이 발생할 수 있는 코드는 최대한 synchrnoized 블록 밖으로 끄집어 내자

### 11.4.2 락 정밀도 높이기

락을 점유하고 있는 시간을 최대한 줄이고, 따라서 락을 확보하기 위해 경쟁하는 시간을 줄일 수 있는 또 다른 방법으로는 바로 스레드에서 해당 락을 덜 사용하도록 변경하는 방법이다.
이런 방법에는
* 락 분할(splitting)
* 락 스트라이핑(striping)

### 11.4.3 락 스트라이핑

락 분할 방법은 때에 따라 독립적인 객체를 여러 가지 크기의 단위로 묶어내고, 묶인 블록을 단위로 락을 나누는 방법을 사용할 수도 있는데, 이런 방법을 `락 스트라이핑(lock striping)`이라고 한다.
예를 들어)
ConcurrentHashMap 클래스가 구현된 소스 코드를 보면 16개의 락을 배열로 마련해두고 16개의 락 각자가 전체 해시 번위의 1/16에 대한 락을 담단한다. 따라서 N번째 해시 값은 락 배열에서 N mod 16의 값에 해당하는 락으로 동기화된다.

### 11.4.4. 핫 필드 최소화

모든 연산에 꼭 필요한 변수가 있다면 락의 정밀도(granularity)를 세밀하게 쪼개는 방법을 적용할 수 없다. 이 부분은 성능과 확장성이 서로 공존하기 어렵게 만드는 또 다른 요인이라고 볼 수 있겠다.
예를 들어, 자주 계산하고 사용하는 값을 캐시에 저장해두도록 최적화한다면 확장성을 떨어뜨릴 수 밖에 없는 `핫 필드(hot fields)`가 나타난다.

모든 연산을 수행할 때마다 한 번씩 사용해야 하는 카운터 변수와 같은 부분을 `핫 필드`라고 부른다.

ConcurrentHashMap 클래스는 전체 카운트를 하나의 변수에 두지 않고, 락으로 분배된 각 부분마다 카운터 변수를 따로 두고 관리하면서 size메소드를 호출하면 각 카운터 변수의 합을 알려주는 방법을 사용한다.

### 11.4.5 독점적인 락을 최소화하는 다른 방법

병렬 컬렉션 클래스를 사용하거나 읽기-쓰기(read-write)락을 사용하거나 불변(immutable)객체를 사용하고, 단일 연산 변수를 사용하는 등의 방법

ReadWriteLock 클래스
* 여러개의 reader가 있고 하나의 writer가 있는 상황
* 여러 개의 스레드에서 공유된 변수의 내용을 읽어가려고 하면 값을 변경하지 못한다.
* 값을 변경할 수 잇는 단 하나의 스레드는 값을 쓸 때 락을 독접적으로 확보한다.
* 읽기 연산이 대부분을 차지하는 데이터 구조에 적용하기 알맞다.

단일 연산 변수(atomic variable)
* 통계 값을 위한 카운터 변수나 일련번호 생성 모듈, 링크로 구성된 데이터 구조에서 첫 번째 항목을 가리키는 링크와 같은 `핫 필드`가 존재할 때 핫 필드의 값을 손쉽게 변경할 수 있게 해준다.

### 11.4.6 CPU 활용도 모니터링

### 11.4.7 객체 풀링은 하지 말자

예전에 객체 관련 할당과 제거 작업이 느렸을 때는 객체를 더 이상 사용하지 않는다 해도 가비지 컬렉터에 넘기는 대신 재사용할 수 있게 보관해두고, 꼭 필요한 경우에만 새로운 객체를 생성하는 객체 풀(object pool)을 많이 활용했었다.
이런 방법을 사용해 가비지 컬렉션에 소모되는 시간을 줄일 수 있다고는 하지만, 그렇다 해도 단일 스레드 애플리케이션에서 아주 무겁고 큰 객체를 제외하고는 일반적으로 성능에 좋지 않은 영향을 미치는 것으로 알려져 있다.

## 11.5 예제: Map 객체의 성능 분석

## 11.6 컨텍스트 스위치 부하 줄이기

로그 출력 작업이 로그 출력만을 전담으로 하는 백그라운드 스레드에 의해서 진행되며, 실제로 로그 메시지를 출력하고자 했던 스레드는 실제로 로그를 출력하지는 않는다.
어떤 추가작업이 있든지 간에 로그 출력 기능에 걸리는 시간은 항상 I/O 스트림 클래스와 관련된 모든 작업 시간을 포함한다. 즉, I/O 연산이 대기 상태에 들어가면 해당 스레드가 대기 중인 시간까지 전체 작업 시간에 포함된다.
이를 로그 출력 전담 스레드에게 맡기면 컨텍스트 스위치 부하를 줄일 수 있다.

## 요약
